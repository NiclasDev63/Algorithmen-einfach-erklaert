# Algorithmen einfach erkl√§rt
Da ich, als ich angefangen habe, Algorithmen zu lernen, leider gr√∂√ütenteils auf rein englisch sprachige Tutorials gesto√üen bin, was nicht unbedingt dabei geholfen hat, sie zu verstehen, dachte ich mir, so etwas m√ºsste es in Deutsch geben.
Aus diesem Grund werde ich in diesem Repository ein paar der bekanntesten Algorithmen in Deutsch n√§her erkl√§ren.
Alle Algorithmen werden f√ºr ein besseres Verst√§ndnis zus√§tzlich zu der Erkl√§rung noch in Python implementiert.
Ich habe mir Python ausgesucht, da diese Programmiersprache auch f√ºr Leser ohne Programmierkenntnisse leicht zu verstehen ist.
<br>
Des weiteren werden Kenntnisse √ºber folgende Datenstrukturen vorausgesetzt, da ich auf diese nicht genauer eingehen werde.
* Array (Listen in Python)
* set
* Queue (FirstInFirstOut) / Stack (LastInFirstOut)
* Graphen


## Grundlegendes Vokabular und Erkl√§rungen
First things first.
### Was ist ein Algorithmus? <br>
Einfach erkl√§rt, ein Algorithmus ist eine Reihe von Anweisungen, die Schritt f√ºr Schritt ausgef√ºhrt werden, um ein bestimmtes Problem, wie beispielsweise das Sortieren einer Liste, zu l√∂sen.
<br>
### Landau-Notation (O-Notation oder auch big O notation)
Wenn du relativ neu im Thema Algorithmen bist, wirst du dir wahrscheinlich die Frage stellen, was ist die Landau-Notation und wozu brauch man sie.
Da in der Informatik das Laufzeitverhalten von Programmen eine wichtige und fundamentale Rolle spielt, muss es eine M√∂glichkeit geben, dieses anzugeben.<br>
Kommen wir nun zu unserem vorherigen Beispiel, dem sortieren einer Liste zur√ºck.<br>
Da die L√§nge einer Liste, welche mit einem Bestimmen Algorithmus sortiert werden soll, meist variabel ist, kann man die Laufzeit des Algorithmus nicht in Sekunden oder Minuten angeben.
Hier kommt die Landau-Notaion (auch O-Notation genannt) ins Spiel.<br>
Diese erm√∂glicht es uns, eine allgemeine Aussage √ºber das Laufzeitverhalten von Algorithmen zu t√§tigen.
<br>
Jetzt folgt eine kleine Erkl√§rung, der h√§ufigsten Notationen.

**O(1)**:
konstante Komplexit√§t, die Laufzeit h√§ngt nicht von der Datenmenge ab.
z.B. Arrayzugriff, Hashtable
<br>
<br>
**O(n)**:
lineare Komplexit√§t, die Laufzeit ist propertional zur Datenmenge.
z.B. Schleife √ºber ein Array um einen Wert zu finden, Einlesen einer Treffermenge aus der Datenbank
<br>
<br>
**O(n¬≤)**:
quadratische Komplexit√§t, eine doppelte Datenmenge vervierfacht die Laufzeit
z.B. Bubble-Sort
<br>
<br>
**O(log n)**:
logarithmische Komplexit√§t, wird die Datenmenge jeweils verdoppelt, steigt die Laufzeit linear an
z.B. Suchb√§ume
<br>
<br>
**O(n log n)**:
superlineare Komplexit√§t, liegt zwischen ùí™(n) und ùí™(n¬≤). Tritt zum Beispiel auf, wenn eine Schleife √ºber eine Baumsuche gebildet wird.
z.B. optimierte Sortieralgorithmen wie Quicksort
<br>
<br>
**O(2‚Åø)**:
exponentielle Komplexit√§t, die Laufzeit verdoppelt sich, wenn die Datenmenge um eine Einheit gr√∂√üer wird.
z.B. Bilden aller Paare einer Menge, T√ºrme von Hanoi als rekursiver Algorithmus
<br>
<br>
**O(n!)**:
faktorielle Komplexit√§t, die Laufzeit w√§chst mit der Fakult√§t der Datenmenge.
z.B. Problem des Handlungsreisenden
<br>
Da es manchen bestimmt trotzdem noch schwerf√§llt, sich darunter was vorzustellen, habe ich hier noch mal ein Bild eingef√ºgt, welches das soeben Beschriebene visuell darstellt.
<br>


![image](https://user-images.githubusercontent.com/83044113/151657832-9b5915d3-65ec-4f43-a859-9e8c630d81ea.png)












